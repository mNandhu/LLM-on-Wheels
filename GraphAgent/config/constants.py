LLM_MODEL = "llama-3.3-70b-versatile"
RESPOND_OR_QUERY_MAX_INVALIDS = 2

# Debug configuration flags
DEBUG_CONFIG = {
    "SHOW_STATE_CHANGES": True,  # Show state changes between nodes
    "SHOW_TIMING": True,  # Show execution time for each step
    "SHOW_DECISION_PROCESS": True,  # Show the task decision process
    "SHOW_CREWAI_DETAILS": True,  # Show CrewAI interaction details
    "COLORED_OUTPUT": True,  # Use colored terminal output
}
